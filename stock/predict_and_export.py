# predict_and_export.py
# -*- coding: utf-8 -*-
import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt
import joblib
from datetime import datetime, timedelta
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

# è¼‰å…¥è‚¡å¸‚è³‡è¨Š
def load_stock_data(stock_code, fallback_dir="."):
    path = os.path.join(fallback_dir, f"fallback_{stock_code}.csv")
    if not os.path.exists(path):
        print(f"âŒ æ‰¾ä¸åˆ° fallback_{stock_code}.csv")
        return None
    df = pd.read_csv(path, parse_dates=["æ—¥æœŸ"])
    df = df.dropna(subset=["æ”¶ç›¤åƒ¹", "æˆäº¤è‚¡æ•¸"])
    df["è‚¡ç¥¨ä»£è™Ÿ"] = stock_code
    df["è‚¡ç¥¨ä»£ç¢¼"] = stock_code
    return df

# ç‰¹å¾µæ¨™ç±¤å»ºç«‹
def build_features(df):
    df = df.copy()
    df["æ”¶ç›¤åƒ¹_shift1"] = df["æ”¶ç›¤åƒ¹"].shift(1)
    df["æ¼²è·Œåƒ¹å·®_shift1"] = df["æ¼²è·Œåƒ¹å·®"].shift(1)
    df["æ”¶ç›¤_5æ—¥å‡ç·š"] = df["æ”¶ç›¤åƒ¹"].rolling(5).mean()
    df["æ”¶ç›¤åƒ¹æ˜æ—¥"] = df["æ”¶ç›¤åƒ¹"].shift(-1)
    df["æ¼²è·Œæ¨™ç±¤"] = (df["æ”¶ç›¤åƒ¹æ˜æ—¥"] > df["æ”¶ç›¤åƒ¹"]).astype(int)
    return df.dropna()

# è¨“ç·´æ¨¡å‹ä¸¦é æ¸¬
def train_and_predict(df_feat, stock_code):
    features = ["æ”¶ç›¤åƒ¹_shift1", "æ¼²è·Œåƒ¹å·®_shift1", "æˆäº¤è‚¡æ•¸", "æ”¶ç›¤_5æ—¥å‡ç·š"]
    X = df_feat[features]
    y_reg = df_feat["æ”¶ç›¤åƒ¹æ˜æ—¥"]

    if len(df_feat) < 20:
        print(f"âš ï¸ {stock_code} è³‡æ–™éå°‘ï¼Œè·³éè¨“ç·´")
        return pd.DataFrame(), None  # å›å‚³ None ä»£è¡¨æ²’æœ‰æ¨¡å‹ RÂ²

    df_feat = df_feat.reset_index(drop=True)
    X = X.reset_index(drop=True)
    y_reg = y_reg.reset_index(drop=True)

    X_train, X_test, y_train, y_test = train_test_split(X, y_reg, test_size=0.2, shuffle=False)

    reg_model = LinearRegression()
    reg_model.fit(X_train, y_train)

    # ğŸŸ© è¨ˆç®— RÂ² æ±ºå®šä¿‚æ•¸
    r2 = reg_model.score(X_test, y_test)
    print(f"æ¨¡å‹ RÂ² æ±ºå®šä¿‚æ•¸ï¼š{r2:.4f}")

    os.makedirs("models", exist_ok=True)
    model_path = f"models/model_{stock_code}.pkl"
    joblib.dump(reg_model, model_path)
    print(f"ğŸ’¾ å·²è¨“ç·´ä¸¦å„²å­˜æ¨¡å‹ï¼š{model_path}")

    y_pred = reg_model.predict(X_test)

    residuals = y_train - reg_model.predict(X_train)
    sigma_squared = np.var(residuals, ddof=X_train.shape[1])
    sigma = np.sqrt(sigma_squared)

    X_train_with_intercept = np.hstack([np.ones((X_train.shape[0], 1)), X_train])
    X_test_with_intercept = np.hstack([np.ones((X_test.shape[0], 1)), X_test])
    cov_matrix = np.linalg.inv(X_train_with_intercept.T @ X_train_with_intercept)

    pred_std = []
    for x0 in X_test_with_intercept:
        std = np.sqrt(sigma_squared * (1 + x0 @ cov_matrix @ x0.T))
        pred_std.append(std)
    pred_std = np.array(pred_std)

    df_result = df_feat.iloc[X_test.index].copy()
    df_result["é æ¸¬æ”¶ç›¤åƒ¹"] = y_pred
    df_result["é æ¸¬æ¨™æº–å·®"] = pred_std
    df_result["é æ¸¬æ”¶ç›¤åƒ¹_ä¸Šç•Œ"] = y_pred + 1.96 * pred_std
    df_result["é æ¸¬æ”¶ç›¤åƒ¹_ä¸‹ç•Œ"] = y_pred - 1.96 * pred_std
    df_result["é æ¸¬æ¼²è·Œ"] = (y_pred > df_result["æ”¶ç›¤åƒ¹"]).astype(int)

    max_std = pred_std.max() if pred_std.max() > 0 else 1
    df_result["ä¿¡å¿ƒåº¦"] = (1 - pred_std / max_std).clip(0, 1)

    return df_result, r2

# è¼‰å…¥æ¨¡å‹ä¸¦é æ¸¬
def load_model_and_predict(df_feat, stock_code):
    model_path = f"models/model_{stock_code}.pkl"
    if not os.path.exists(model_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹ï¼š{model_path}")
        return pd.DataFrame()

    reg_model = joblib.load(model_path)
    print(f"ğŸ“¥ è¼‰å…¥æ¨¡å‹ï¼š{model_path}")

    features = ["æ”¶ç›¤åƒ¹_shift1", "æ¼²è·Œåƒ¹å·®_shift1", "æˆäº¤è‚¡æ•¸", "æ”¶ç›¤_5æ—¥å‡ç·š"]
    X = df_feat[features].reset_index(drop=True)
    df_feat = df_feat.reset_index(drop=True)

    y_pred = reg_model.predict(X)

    residuals = df_feat["æ”¶ç›¤åƒ¹æ˜æ—¥"].iloc[:-1] - reg_model.predict(X.iloc[:-1])
    sigma_squared = np.var(residuals, ddof=X.shape[1])
    sigma = np.sqrt(sigma_squared)

    X_with_intercept = np.hstack([np.ones((X.shape[0], 1)), X])
    cov_matrix = np.linalg.inv(X_with_intercept.T @ X_with_intercept)

    pred_std = []
    for x0 in X_with_intercept:
        std = np.sqrt(sigma_squared * (1 + x0 @ cov_matrix @ x0.T))
        pred_std.append(std)
    pred_std = np.array(pred_std)

    df_result = df_feat.copy()
    df_result["é æ¸¬æ”¶ç›¤åƒ¹"] = y_pred
    df_result["é æ¸¬æ¨™æº–å·®"] = pred_std
    df_result["é æ¸¬æ”¶ç›¤åƒ¹_ä¸Šç•Œ"] = y_pred + 1.96 * pred_std
    df_result["é æ¸¬æ”¶ç›¤åƒ¹_ä¸‹ç•Œ"] = y_pred - 1.96 * pred_std
    df_result["é æ¸¬æ¼²è·Œ"] = (y_pred > df_result["æ”¶ç›¤åƒ¹"]).astype(int)

    max_std = pred_std.max() if pred_std.max() > 0 else 1
    df_result["ä¿¡å¿ƒåº¦"] = (1 - pred_std / max_std).clip(0, 1)

    return df_result

# åˆ¤æ–·æ˜¯å¦å­˜åœ¨æ¨¡å‹æª”æ¡ˆï¼Œæœ‰å‰‡è¼‰å…¥ï¼Œç„¡å‰‡è¨“ç·´ä¸¦å„²å­˜
def ensure_model_and_predict(df_feat, stock_code):
    model_path = f"models/model_{stock_code}.pkl"
    if os.path.exists(model_path):
        return load_model_and_predict(df_feat, stock_code)
    else:
        return train_and_predict(df_feat, stock_code)

# é æ¸¬å¤šç­†æ¨™çš„æ”¶ç›¤åƒ¹
def predict_multiple_stocks(stock_codes):
    all_results = []
    for code in stock_codes:
        df = load_stock_data(code)
        if df is None:
            continue
        df_feat = build_features(df)
        df_pred = ensure_model_and_predict(df_feat, stock_code=code)
        df_pred["è‚¡ç¥¨ä»£è™Ÿ"] = code
        df_pred["è‚¡ç¥¨ä»£ç¢¼"] = code
        all_results.append(df_pred)
    return pd.concat(all_results, ignore_index=True) if all_results else pd.DataFrame()

# ç¹ªå‡ºè¿‘åå¤©çš„æ”¶ç›¤åƒ¹èµ°å‹¢åœ–
def plot_predictions_ten(df_result, output_dir=".", prop=None):
    os.makedirs(output_dir, exist_ok=True)
    grouped = df_result.groupby("è‚¡ç¥¨ä»£ç¢¼")

    for code, group in grouped:
        last_date = group["æ—¥æœŸ"].max()
        pred_date = last_date + timedelta(days=1)
        start_date = pred_date - timedelta(days=10)
        df_zoom = group[(group["æ—¥æœŸ"] >= start_date) & (group["æ—¥æœŸ"] <= pred_date)].copy()

        if df_zoom.empty:
            print(f"âš ï¸ {code} åœ¨é æ¸¬æ—¥å‰ 10 å¤©å…§æ²’æœ‰è³‡æ–™ï¼Œè·³éåœ–è¡¨")
            continue

        plt.figure(figsize=(10, 5))
        plt.plot(df_zoom["æ—¥æœŸ"], df_zoom["æ”¶ç›¤åƒ¹"], label="å¯¦éš›æ”¶ç›¤åƒ¹", alpha=0.8)
        plt.plot(df_zoom["æ—¥æœŸ"], df_zoom["é æ¸¬æ”¶ç›¤åƒ¹"], linestyle='--', label="é æ¸¬æ”¶ç›¤åƒ¹", alpha=0.8)
        plt.axvline(pred_date, color="red", linestyle=":", label="é æ¸¬æ—¥")
        plt.xticks(rotation=45)
        plt.xticks(fontproperties=prop)
        plt.yticks(fontproperties=prop)

        stock_name = df_zoom["æœ‰åƒ¹è­‰åˆ¸ä»£è™Ÿåç¨±"].iloc[0]
        title = f"{code} {stock_name} æ”¶ç›¤åƒ¹è¶¨å‹¢ï¼ˆé æ¸¬æ—¥å‰10å¤©ï¼‰"
        plt.title(title, fontproperties=prop)
        plt.xlabel("æ—¥æœŸ", fontproperties=prop)
        plt.ylabel("æ”¶ç›¤åƒ¹", fontproperties=prop)
        plt.legend(prop=prop)
        plt.grid(True)
        plt.tight_layout()

        filename = os.path.join(output_dir, f"price_prediction_{code}_ten.png")
        plt.savefig(filename)
        print(f"ğŸ“ˆ å·²å„²å­˜åœ–æª”ï¼š{filename}")
        plt.close()

# ç¹ªå‡ºä¸Šå¸‚æ—¥è‡³é æ¸¬æ—¥çš„æ”¶ç›¤åƒ¹èµ°å‹¢åœ–
def plot_predictions_all(df_result, output_dir=".", prop=None):
    os.makedirs(output_dir, exist_ok=True)
    grouped = df_result.groupby("è‚¡ç¥¨ä»£ç¢¼")
    for code, group in grouped:
        plt.figure(figsize=(10, 5))
        plt.plot(group["æ—¥æœŸ"], group["æ”¶ç›¤åƒ¹"], label="å¯¦éš›æ”¶ç›¤åƒ¹", alpha=0.8)
        plt.plot(group["æ—¥æœŸ"], group["é æ¸¬æ”¶ç›¤åƒ¹"], linestyle='--', label="é æ¸¬æ”¶ç›¤åƒ¹", alpha=0.8)
        plt.xticks(rotation=45)
        plt.xticks(fontproperties=prop)
        plt.yticks(fontproperties=prop)

        stock_name = group["æœ‰åƒ¹è­‰åˆ¸ä»£è™Ÿåç¨±"].iloc[0]
        title = f"{code} {stock_name} æ”¶ç›¤åƒ¹é æ¸¬"
        plt.title(title, fontproperties=prop)
        plt.xlabel("æ—¥æœŸ", fontproperties=prop)
        plt.ylabel("æ”¶ç›¤åƒ¹", fontproperties=prop)
        plt.legend(prop=prop)
        plt.grid(True)
        plt.tight_layout()

        filename = os.path.join(output_dir, f"price_prediction_{code}_all.png")
        plt.savefig(filename)
        print(f"ğŸ“ˆ å·²å„²å­˜åœ–æª”ï¼š{filename}")
        plt.close()

#ã€€è¼¸å‡ºçµæœçµ±æ•´å ±è¡¨
def export_prediction_summary(df_result, output_path="prediction_report.xlsx"):
    today_str = datetime.today().strftime("%Y/%m/%d")
    latest = df_result.sort_values("æ—¥æœŸ").groupby("è‚¡ç¥¨ä»£è™Ÿ").tail(1).copy()
    latest["é æ¸¬æ—¥æœŸ"] = (pd.Timestamp.today() + pd.Timedelta(days=1)).strftime("%Y/%m/%d")
    latest["ä»Šå¤©æ—¥æœŸ"] = today_str
    latest["æ¼²è·Œçµæœ"] = latest["é æ¸¬æ¼²è·Œ"].map({1: "â†‘ æ¼²", 0: "â†“ è·Œ"})
    latest["ä¿¡å¿ƒåº¦"] = (latest["ä¿¡å¿ƒåº¦"] * 100).round(2).astype(str) + "%"
    latest["é–‹ç›¤æ—¥"] = latest["æ—¥æœŸ"].dt.strftime("%Y/%m/%d")

    summary = latest[[
        "ä»Šå¤©æ—¥æœŸ", "é æ¸¬æ—¥æœŸ", "é–‹ç›¤æ—¥", "è‚¡ç¥¨ä»£è™Ÿ", "æœ‰åƒ¹è­‰åˆ¸ä»£è™Ÿåç¨±",
        "æ”¶ç›¤åƒ¹", "é æ¸¬æ”¶ç›¤åƒ¹", "é æ¸¬æ”¶ç›¤åƒ¹_ä¸‹ç•Œ", "é æ¸¬æ”¶ç›¤åƒ¹_ä¸Šç•Œ", "æ¼²è·Œçµæœ", "ä¿¡å¿ƒåº¦"
    ]].copy()

    summary["æ”¶ç›¤åƒ¹"] = summary["æ”¶ç›¤åƒ¹"].round(2)
    summary["é æ¸¬æ”¶ç›¤åƒ¹"] = summary["é æ¸¬æ”¶ç›¤åƒ¹"].round(2)
    summary["é æ¸¬æ”¶ç›¤åƒ¹_ä¸‹ç•Œ"] = summary["é æ¸¬æ”¶ç›¤åƒ¹_ä¸‹ç•Œ"].round(2)
    summary["é æ¸¬æ”¶ç›¤åƒ¹_ä¸Šç•Œ"] = summary["é æ¸¬æ”¶ç›¤åƒ¹_ä¸Šç•Œ"].round(2)
    summary.to_excel(output_path, index=False)
    print(f"ğŸ“Š é æ¸¬å ±å‘Šå·²è¼¸å‡ºè‡³ï¼š{output_path}")
